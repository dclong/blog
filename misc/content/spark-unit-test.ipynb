{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title: Unit Testing for Spark\n",
    "- Slug: spark-unit-test\n",
    "- Date: 2019-11-26\n",
    "- Category: Computer Science\n",
    "- Tags: programming, Scala, Spark, unit testing, unit test\n",
    "- Author: Ben Du"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Analyzer\n",
    "\n",
    "If we get the execuation plan, \n",
    "then it is quite easy to analyze ...\n",
    "\n",
    "\n",
    "https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-lineage.html\n",
    "\n",
    "https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-dependencies.html\n",
    "\n",
    "http://hydronitrogen.com/in-the-code-spark-sql-query-planning-and-execution.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Testing Frameworks/Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use Scala testing frameworks ScalaTest (recommended) and Specs, \n",
    "or you can use frameworks/tools developed based on them for Spark specifically.\n",
    "Various discussions suggests that **Spark Testing Base** is a good one.\n",
    "\n",
    "https://www.slideshare.net/SparkSummit/beyond-parallelize-and-collect-by-holden-karau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Unit Testing\n",
    "\n",
    "1. [Spark Testing Base](https://github.com/holdenk/spark-testing-base)\n",
    "\n",
    "3. [sscheck](https://github.com/juanrh/sscheck)\n",
    "\n",
    "### Spark Performance Test\n",
    "\n",
    "https://github.com/databricks/spark-perf\n",
    "\n",
    "### Spark Integration Test\n",
    "\n",
    "https://github.com/databricks/spark-integration-tests\n",
    "\n",
    "### Spark Job Validation\n",
    "\n",
    "https://www.slideshare.net/SparkSummit/beyond-parallelize-and-collect-by-holden-karau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QuickCheck/ScalaCheck \n",
    "\n",
    "1. QuickCheck generates tests data under a set of constraints \n",
    "2. Scala version is ScalaCheck supported by the two unit testing libraries for Spark \n",
    "    - sscheck\n",
    "        + Awesome people\n",
    "        + supports generating DStreams too! \n",
    "    - spark-testing-base \n",
    "        + Awesome people\n",
    "        + generates more pathological (e.g. empty partitions etc.) RDDs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Spark Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good Discussions\n",
    "\n",
    "http://blog.ippon.tech/testing-strategy-apache-spark-jobs/\n",
    "\n",
    "http://blog.ippon.tech/testing-strategy-for-spark-streaming/\n",
    "\n",
    "https://www.youtube.com/watch?v=rOQEiTXNS0g\n",
    "\n",
    "https://www.slideshare.net/SparkSummit/beyond-parallelize-and-collect-by-holden-karau\n",
    "\n",
    "https://medium.com/@mrpowers/validating-spark-dataframe-schemas-28d2b3c69d2a\n",
    "\n",
    "### More\n",
    "\n",
    "https://medium.com/@mrpowers/testing-spark-applications-8c590d3215fa\n",
    "\n",
    "http://mkuthan.github.io/blog/2015/03/01/spark-unit-testing/\n",
    "\n",
    "https://dzone.com/articles/testing-spark-code\n",
    "\n",
    "https://spark-summit.org/2014/wp-content/uploads/2014/06/Testing-Spark-Best-Practices-Anupama-Shetty-Neil-Marshall.pdf\n",
    "\n",
    "https://blog.cloudera.com/blog/2015/09/making-apache-spark-testing-easy-with-spark-testing-base/\n",
    "\n",
    "https://opencredo.com/spark-testing/\n",
    "\n",
    "http://eugenezhulenev.com/blog/2014/10/18/run-tests-in-standalone-spark-cluster/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator \n",
    "\n",
    "[This discussion on StackOverflow](https://stackoverflow.com/questions/591892/tools-for-generating-mock-data) suggests that Databene Benerator is good choice.\n",
    "\n",
    "Question: Does any tool support generating data sets that gurantees that joining returns results? And best if the returned results conver different corner cases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Tools\n",
    "\n",
    "1. http://www.softwaretestinghelp.com/tools/40-best-database-testing-tools/\n",
    "\n",
    "1. http://filldb.info/\n",
    "\n",
    "1. [DataGenerator](https://github.com/FINRAOS/DataGenerator)\n",
    "\n",
    "    - handles dependencies\n",
    "    - for Java\n",
    "\n",
    "1. [Databene Benerator ](http://databene.org/databene-benerator)\n",
    "    - handles dependencies \n",
    "    - poor documentation\n",
    "\n",
    "2. [mocker-data-generator](https://github.com/danibram/mocker-data-generator)\n",
    "    - JS based\n",
    "\n",
    "## Others\n",
    "\n",
    "3. [Online Generate CSV Test Data](http://www.convertcsv.com/generate-test-data.htm)\n",
    "    - doesn't handle dependencies\n",
    "    - simple and easy to use\n",
    "\n",
    "4. [GenerateData](https://www.generatedata.com/)\n",
    "    - doesn't handle dependencies\n",
    "    - simple and easy to use\n",
    "    - able to share it with people\n",
    "\n",
    "5. [Mockaroo](https://www.mockaroo.com)\n",
    "\n",
    "    - doesn't handle dependencies\n",
    "    - simple and easy to use\n",
    "\n",
    "## Commerical Tools\n",
    "\n",
    "1. [SQL Data Generator](https://www.red-gate.com/products/sql-development/sql-data-generator/)\n",
    "\n",
    "    - handles dependencis\n",
    "\n",
    "2. ApexSQL SQL test data generator\n",
    "\n",
    "## More\n",
    "\n",
    "1. https://jethro.io/blog/how-to-generate-mock-data-for-testing\n",
    "\n",
    "2. http://www.bigsynapse.com/sampling-large-datasets-using-spark\n",
    "\n",
    "3. http://www.bizdatax.com/wp-content/uploads/2015/10/blog-how-to-mask-subset-and-generate-test-data-Img2.png\n",
    "\n",
    "4. https://github.com/18F/rdbms-subsetter\n",
    "\n",
    "5. https://docops.ca.com/ca-test-data-manager/3-5/en\n",
    "\n",
    "6. http://finraos.github.io/DataGenerator/\n",
    "\n",
    "7. http://sqlblog.com/blogs/jamie_thomson/archive/2009/09/08/deriving-a-list-of-tables-in-dependency-order.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sanity Checking\n",
    "\n",
    "http://databene.org/dbsanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Testing Tools\n",
    "\n",
    "\n",
    "[Comparison of Locust and Other Load Testing Tools](https://news.ycombinator.com/item?id=9810274)\n",
    "\n",
    "[Open Source Load Testing Tool Review](http://blog.loadimpact.com/open-source-load-testing-tool-review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locust \n",
    "\n",
    "Locust is a tool/framework for writing code that simulates real user behaviour in a fairly realistic way. For example, it's very common to store state for each simulated user. Once you have written your \"user behaviour code\", you can then simulate a lot of simultaneous users by running it distributed across multiple machines, and hopefully get realistic load sent to you system.\n",
    "\n",
    "If I wanted to just send a lot of requests/s to one or very few URL endpoints, I would also use something like ApacheBench, and I'm author of Locust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ApacheBench](https://en.wikipedia.org/wiki/ApacheBench)\n",
    "\n",
    "ApacheBench (ab) is a single-threaded command line computer program \n",
    "for measuring the performance of HTTP web servers.[1] \n",
    "Originally designed to test the Apache HTTP Server, \n",
    "it is generic enough to test any web server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [PipelineAI](http://pipeline.ai/) looks really interesting!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " val sparkSession: SparkSession = SparkSession.builder()\n",
    "      .master(\"local[2]\")\n",
    "      .appName(\"TestSparkApp\")\n",
    "      .config(\"spark.sql.shuffle.partitions\", \"1\")\n",
    "      .config(\"spark.sql.warehouse.dir\", \"java.io.tmpdir\")\n",
    "      .getOrCreate()\n",
    "  import sparkSession.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/sql/Dataset.html\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/sql/functions.html\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/Row.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "",
   "name": "Scala",
   "nbconverter_exporter": "",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}