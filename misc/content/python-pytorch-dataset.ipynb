{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title: Tips on Dataset in PyTorch\n",
    "- Slug: python-pytorch-dataset\n",
    "- Date: 2020-02-26 22:40:06\n",
    "- Category: Programming\n",
    "- Tags: programming, Python, AI, data science, machine learning, deep learning, PyTorch, Dataset\n",
    "- Author: Ben Du"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. It is a good practice to save your data (e.g., images) into one pickle file\n",
    "   (or other format that you know how to deserialize).\n",
    "    This comes with several advantages.\n",
    "    First, it is easier and faster to read from a single big file rather than many small files. \n",
    "    Second, it avoids the system error of openning too many files.\n",
    "    Some example datasets (e.g., MNIST)\n",
    "    have separate training and testing files (i.e., 2 pickle files), \n",
    "    so that research work based on it can be easily reproduced.\n",
    "    I personally suggest that you keep only 1 file containing all data\n",
    "    when implementing your own Dataset class.\n",
    "    You can always use the function `torch.utils.data.random_split`\n",
    "    to split your dataset into training and testing datasets later.\n",
    "    For more details, \n",
    "    please refer to \n",
    "    [http://www.legendu.net/misc/blog/python-ai-split-dataset/](http://www.legendu.net/misc/blog/python-ai-split-dataset/#PyTorch).\n",
    "    \n",
    "1. When you implement your own Dataset class,\n",
    "    you need to inherit from \n",
    "    [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)\n",
    "    (or one of its subclasses).\n",
    "    You must overwrite the 2 methods `__len__` and `__getitem__`.\n",
    "\n",
    "2. When you implement your own Dataset class for image classification,\n",
    "    it is best to inherit from \n",
    "    [torchvision.datasets.vision.VisionDataset](https://github.com/pytorch/vision/blob/master/torchvision/datasets/vision.py#L6)\n",
    "    .\n",
    "    For example, \n",
    "    [torchvision.datasets.MNIST](https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py)\n",
    "    subclasses \n",
    "    [torchvision.datasets.vision.VisionDataset](https://github.com/pytorch/vision/blob/master/torchvision/datasets/vision.py#L6)\n",
    "    . \n",
    "    You can use it as a template.\n",
    "    Notice you still only have to overwrite the 2 methods `__len__` and `__getitem__`\n",
    "    (even though the implementation of \n",
    "    [torchvision.datasets.MNIST](https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py)\n",
    "    is much more complicated than that).\n",
    "    [torchvision.datasets.MNIST](https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py)\n",
    "    downloads data into the directory `MNIST/raw` \n",
    "    and make a copy of ready-to-use data into the directory `MNIST/processed`. \n",
    "    It doesn't matter whether you follow this convention or not\n",
    "    as long as you overwrite the 2 methods `__len__` and `__getitem__`.\n",
    "    What's more, the parameter `root` for the constructor of \n",
    "    [torchvision.datasets.vision.VisionDataset](https://github.com/pytorch/vision/blob/master/torchvision/datasets/vision.py#L6)\n",
    "    is not critical \n",
    "    as long as your Dataset subclass knows where and how to load the data\n",
    "    (e.g., you can pass the full path of the data file as parameter for your Dataset subclass). \n",
    "    You can set it to `None` if you like. \n",
    "  \n",
    "\n",
    "3. When you implement a Dataset class for image classification,\n",
    "    it is best to have the method `__getitem__` return `(PIL.Image, target)`\n",
    "    and then use `torchvision.transforms.ToTensor` to convert `PIL.Image` to tensor\n",
    "    in the DataLoader.\n",
    "    The reason is that transforming modules in `trochvision.transforms` \n",
    "    behave differently on `PIL.Image` \n",
    "    and their equivalent numpy array. \n",
    "    You might get surprises if you have `__getitem__` return `(torch.Tensor, target)`.\n",
    "    If you do have `__getitem__` return `(torch.Tensor, target)`,\n",
    "    make sure to double check that they tensors are as expected \n",
    "    before feeding them into your model for training/prediction.\n",
    "\n",
    "4. `torchvision.transforms.ToTensor` (refered to as `ToTensor` in the following) \n",
    "    converts a `PIL.Image` to a numerical tensor with each value between [0, 1].\n",
    "    `ToTensor` on a boolean numpy array (representing a black/white image) \n",
    "    returns a boolean tensor (instead of converting it to a numeric tensor). \n",
    "    This is one reason that you should return `(PIL.Image, target)` \n",
    "    and avoid returning `(numpy.array, target)`\n",
    "    when implement your own Dataset class for image classification.\n",
    "        \n",
    "5. There is no need to return the target as a `torch.Tensor` (even though you can)\n",
    "    when you implement the method `__getitem__` of your own Dataset class.\n",
    "    The DataLoader will convert the batch of target values to `torch.Tensor` automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True, False],\n",
       "       [ True, False,  True]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[True, True, False], [True, False, True]])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True, False],\n",
       "         [ True, False,  True]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = trans(arr)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py\n",
    "\n",
    "[VisionDataset](https://github.com/pytorch/vision/blob/master/torchvision/datasets/vision.py#L6)\n",
    "\n",
    "https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
    "\n",
    "https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "\n",
    "https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
