{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title: Rename Columns in Spark DataFrames\n",
    "- Slug: spark-rename-columns\n",
    "- Date: 2019-12-18\n",
    "- Category: Programming\n",
    "- Tags: programming, Scala, Spark, DataFrame, rename, column\n",
    "- Author: Ben Du"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment\n",
    "\n",
    "You can use `withColumnRenamed` to rename a column in a DataFrame.\n",
    "You can also do renaming using `alias` when select columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f7fac4-ce8c-4724-815a-ee598da59056",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%classpath add mvn\n",
    "org.apache.spark spark-core_2.11 2.3.1\n",
    "org.apache.spark spark-sql_2.11 2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession$implicits$@72bf6e43"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "    .master(\"local[2]\")\n",
    "    .appName(\"Spark Column Example\")\n",
    "    .config(\"spark.some.config.option\", \"some-value\")\n",
    "    .getOrCreate()\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+\n",
      "| X1| X2| X3| X4|\n",
      "+---+---+---+---+\n",
      "|  1|  a|foo|3.0|\n",
      "|  2|  b|bar|4.0|\n",
      "|  3|  c|foo|5.0|\n",
      "|  4|  d|bar|7.0|\n",
      "+---+---+---+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = Seq(\n",
    "    (1L, \"a\", \"foo\", 3.0),\n",
    "    (2L, \"b\", \"bar\", 4.0),\n",
    "    (3L, \"c\", \"foo\", 5.0),\n",
    "    (4L, \"d\", \"bar\", 7.0)\n",
    ").toDF(\"X1\", \"X2\", \"X3\", \"X4\")\n",
    "df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bad"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val b = if(false) \"Good\" \n",
    "        else \"Bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bad"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.option(\"header\", \"true\").mode(\"overwrite\").csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "77",
     "output_type": "error",
     "text": "<console>:77: error: value toDF is not a member of Seq[(Long, String, String, Double)]\npossible cause: maybe a semicolon is missing before `value toDF'?\n       ).toDF\n         ^\n",
     "traceback": [
      "\u001b[1;31m<console>:77: error: value toDF is not a member of Seq[(Long, String, String, Double)]\u001b[0;0m",
      "\u001b[1;31mpossible cause: maybe a semicolon is missing before `value toDF'?\u001b[0;0m",
      "\u001b[1;31m       ).toDF\u001b[0;0m",
      "\u001b[1;31m         ^\u001b[0;0m"
     ]
    }
   ],
   "source": [
    "val df = Seq(\n",
    "    (1L, \"a\", \"foo\", 3.0),\n",
    "    (2L, \"b\", \"bar\", 4.0),\n",
    "    (3L, \"c\", \"foo\", 5.0),\n",
    "    (4L, \"d\", \"bar\", 7.0)\n",
    ").toDF\n",
    "df.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming One Column Using `withColumnRenamed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+\n",
      "| x1| _2| _3| _4|\n",
      "+---+---+---+---+\n",
      "|  1|  a|foo|3.0|\n",
      "|  2|  b|bar|4.0|\n",
      "|  3|  c|foo|5.0|\n",
      "|  4|  d|bar|7.0|\n",
      "+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"_1\", \"x1\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming One Column Using `alias`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+\n",
      "| x1| _2| _3| _4|\n",
      "+---+---+---+---+\n",
      "|  1|  a|foo|3.0|\n",
      "|  2|  b|bar|4.0|\n",
      "|  3|  c|foo|5.0|\n",
      "|  4|  d|bar|7.0|\n",
      "+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    $\"_1\".alias(\"x1\"),\n",
    "    $\"_2\",\n",
    "    $\"_3\",\n",
    "    $\"_4\"\n",
    ").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Renaming Using `withColumnRenamed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+\n",
      "| x1| x2| x3| _4|\n",
      "+---+---+---+---+\n",
      "|  1|  a|foo|3.0|\n",
      "|  2|  b|bar|4.0|\n",
      "|  3|  c|foo|5.0|\n",
      "|  4|  d|bar|7.0|\n",
      "+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lookup.foldLeft(df) {\n",
    "    (acc, ca) => acc.withColumnRenamed(ca._1, ca._2)\n",
    "}.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Renaming Using `alias`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+\n",
      "| x1| x2| x3| _4|\n",
      "+---+---+---+---+\n",
      "|  1|  a|foo|3.0|\n",
      "|  2|  b|bar|4.0|\n",
      "|  3|  c|foo|5.0|\n",
      "|  4|  d|bar|7.0|\n",
      "+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val spark = SparkSession.\n",
    "    builder().\n",
    "    appName(\"Spark SQL basic example\").\n",
    "    config(\"spark.some.config.option\", \"some-value\").\n",
    "    getOrCreate()\n",
    "spark\n",
    "\n",
    "val lookup = Map(\"_1\" -> \"x1\", \"_2\" -> \"x2\", \"_3\" -> \"x3\")\n",
    "\n",
    "df.select(df.columns.map(c => col(c).alias(lookup.getOrElse(c, c))): _*).show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "",
   "name": "Scala",
   "nbconverter_exporter": "",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
