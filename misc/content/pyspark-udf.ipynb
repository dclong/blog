{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title: User-defined Function (UDF) in PySpark\n",
    "- Slug: pyspark-udf\n",
    "- Date: 2020-06-18 08:43:44\n",
    "- Category: Computer Science\n",
    "- Tags: programming, Python, HPC, high performance computing, PySpark, UDF\n",
    "- Author: Ben Du"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "1. The easist way to define a UDF in PySpark is to use the `@udf` tag.\n",
    "\n",
    "2. You need to specify the return type of the UDF, \n",
    "    e.g., `StringType()`. \n",
    "    Notice that you can use the string version of the return type,\n",
    "    e.g., `\"string\"` for `StringType()`.\n",
    "    The string version is simpler to use as you do not have to import the corresponding types\n",
    "    and string versions are short to type. \n",
    "    However, \n",
    "    it is at a slight cost of losing the ability to do static type checking (e.g., using pylint) on the used return types. \n",
    "    \n",
    "3. An UDF can take multiple columns as parameters.\n",
    "\n",
    "4. When invoking a UDF, \n",
    "    you can either pass column expression (e.g., `col(\"name\")`)\n",
    "    or the name of the column (e.g., `\"name\"`) directly to it.\n",
    "    It is suggested that you pass column names to an UDF\n",
    "    as it is simple and passing `col(\"name\")` requires the column name anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import findspark\n",
    "findspark.init(\"/opt/spark-3.0.0-bin-hadoop3.2/\")\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, StringType, StructType\n",
    "spark = SparkSession.builder.appName(\"PySpark UDF\").enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+\n",
      "|name| id|age|\n",
      "+----+---+---+\n",
      "| Ben|  2| 30|\n",
      "| Dan|  4| 25|\n",
      "|Will|  1| 26|\n",
      "+----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_p = pd.DataFrame(data=[\n",
    "    [\"Ben\", 2, 30],\n",
    "    [\"Dan\", 4, 25],\n",
    "    [\"Will\", 1, 26],\n",
    "], columns=[\"name\", \"id\", \"age\"])\n",
    "df = spark.createDataFrame(df_p)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDF Taking One Column as Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(StringType())\n",
    "def say_hello(name: str) -> str:\n",
    "     return f\"Hello {name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+----------+\n",
      "|name| id|age| greetings|\n",
      "+----+---+---+----------+\n",
      "| Ben|  2| 30| Hello Ben|\n",
      "| Dan|  4| 25| Hello Dan|\n",
      "|Will|  1| 26|Hello Will|\n",
      "+----+---+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"greetings\", say_hello(col(\"name\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDF Taking Two Columns as Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(\"string\")\n",
    "def concat(name: str, age: int) -> str:\n",
    "     return f\"{name} is {age} years old.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+--------------------+\n",
      "|name| id|age|           greetings|\n",
      "+----+---+---+--------------------+\n",
      "| Ben|  2| 30|Ben is 30 years old.|\n",
      "| Dan|  4| 25|Dan is 25 years old.|\n",
      "|Will|  1| 26|Will is 26 years ...|\n",
      "+----+---+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"greetings\", concat(col(\"name\"), col(\"age\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+--------------------+\n",
      "|name| id|age|           greetings|\n",
      "+----+---+---+--------------------+\n",
      "| Ben|  2| 30|Ben is 30 years old.|\n",
      "| Dan|  4| 25|Dan is 25 years old.|\n",
      "|Will|  1| 26|Will is 26 years ...|\n",
      "+----+---+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"greetings\", concat(\"name\", \"age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas UDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(\"integer\")\n",
    "def age_plus_one(age: pd.Series) -> pd.Series:\n",
    "     return age + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+----+\n",
      "|name| id|age|age2|\n",
      "+----+---+---+----+\n",
      "| Ben|  2| 30|  31|\n",
      "| Dan|  4| 25|  26|\n",
      "|Will|  1| 26|  27|\n",
      "+----+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"age2\", age_plus_one(\"age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(\"integer\")\n",
    "def age_plus_one(age: pd.Series) -> pd.Series:\n",
    "     return pd.Series(a + 1 for a in age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+----+\n",
      "|name| id|age|age2|\n",
      "+----+---+---+----+\n",
      "| Ben|  2| 30|  31|\n",
      "| Dan|  4| 25|  26|\n",
      "|Will|  1| 26|  27|\n",
      "+----+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"age2\", age_plus_one(\"age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(\"string\")\n",
    "def concat(name: pd.Series, age: pd.Series) -> pd.Series:\n",
    "     return name + \" is \" + \"age years old.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+--------------------+\n",
      "|name| id|age|               intro|\n",
      "+----+---+---+--------------------+\n",
      "| Ben|  2| 30|Ben is age years ...|\n",
      "| Dan|  4| 25|Dan is age years ...|\n",
      "|Will|  1| 26|Will is age years...|\n",
      "+----+---+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"intro\", concat(\"name\", \"age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(\"string\")\n",
    "def concat2(name: pd.Series, age: pd.Series) -> pd.Series:\n",
    "     return pd.Series(f\"{name} is {age} years old.\" for name, age in zip(name, age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+--------------------+\n",
      "|name| id|age|               intro|\n",
      "+----+---+---+--------------------+\n",
      "| Ben|  2| 30|Ben is 30 years old.|\n",
      "| Dan|  4| 25|Dan is 25 years old.|\n",
      "|Will|  1| 26|Will is 26 years ...|\n",
      "+----+---+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"intro\", concat2(\"name\", \"age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://medium.com/@ayplam/developing-pyspark-udfs-d179db0ccc87\n",
    "    \n",
    "https://docs.databricks.com/spark/latest/spark-sql/udf-python.html\n",
    "    \n",
    "https://changhsinlee.com/pyspark-udf/\n",
    "    \n",
    "https://medium.com/@ayplam/developing-pyspark-udfs-d179db0ccc87\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
