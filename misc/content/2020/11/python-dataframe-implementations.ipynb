{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.9.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Ben Du\n",
    "- Date: 2021-04-21 11:10:17\n",
    "- Title: DataFrame Implementations in Python\n",
    "- Slug: scaling-pandas\n",
    "- Category: Computer Science\n",
    "- Tags: Computer Science, programming, Python, DataFrame, pandas, PySpark, Vaex, Modin, Dask, RAPIDS, cudf, cylon"
   ]
  },
  {
   "source": [
    " ** Things on this page are fragmentary and immature notes/thoughts of the author. Please read with your own judgement! **  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## pandas DataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## [dask.DataFrame](https://github.com/dask/dask)\n",
    "\n",
    "Dask is a low-level scheduler and a high-level partial Pandas replacement, \n",
    "geared toward running code on compute clusters.\n",
    "Dask provides `dask.dataframe`,\n",
    "a higher-level, Pandas-like library that can help you deal with out-of-core datasets.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## [vaex](https://github.com/vaexio/vaex)\n",
    "\n",
    "Vaex is a high performance Python library for lazy Out-of-Core DataFrames (similar to Pandas), \n",
    "to visualize and explore big tabular datasets. \n",
    "It calculates statistics such as mean, sum, count, standard deviation etc, \n",
    "on an N-dimensional grid for more than a billion (10^9) samples/rows per second. \n",
    "Visualization is done using histograms, density plots and 3d volume rendering, \n",
    "allowing interactive exploration of big data. \n",
    "Vaex uses memory mapping, zero memory copy policy and lazy computations for best performance (no memory wasted).\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## [cylon](https://github.com/cylondata/cylon)\n",
    "\n",
    "Cylon is a fast, scalable distributed memory data parallel library for processing structured data. \n",
    "Cylon implements a set of relational operators to process data. \n",
    "While \u201dCore Cylon\u201d is implemented using system level C/C++, \n",
    "multiple language interfaces (Python and Java ) are provided to seamlessly integrate with existing applications, \n",
    "enabling both data and AI/ML engineers to invoke data processing operators in a familiar programming language. \n",
    "By default it works with MPI for distributing the applications.\n",
    "Internally Cylon uses Apache Arrow to represent the data in a column format."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## [cudf](https://github.com/rapidsai/cudf)\n",
    "\n",
    "cudf (developed by RAPIDS) is built based on the Apache Arrow columnar memory format, \n",
    "cuDF is a GPU DataFrame library for loading, joining, aggregating, filtering, and otherwise manipulating data.\n",
    "cuDF provides a pandas-like API that will be familiar to data engineers & data scientists, \n",
    "so they can use it to easily accelerate their workflows without going into the details of CUDA programming."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## modin\n",
    "\n",
    "Modin, with Ray as a backend. By installing these, you might see significant benefit by changing just a single line (`import pandas as pd` to `import modin.pandas as pd`). Unlike the other tools, Modin aims to reach full compatibility with Pandas.\n",
    "\n",
    "Modin: a drop-in replacement for Pandas, powered by either Dask or Ray.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## PySpark DataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## TODO\n",
    "\n",
    "1. compare PySpark DataFrame vs Vaex on a single machine ..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## References\n",
    "\n",
    "- [Scaling Pandas: Comparing Dask, Ray, Modin, Vaex, and RAPIDS](https://www.datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray#:~:text=Vaex,-Dask%20(Dataframe)%20is&text=Ultimately%2C%20Dask%20is%20more%20focused,on%20data%20processing%20and%20wrangling.)\n",
    "\n",
    "- [RIP Pandas 2.0: Time For DASK After VAEX !!!](https://towardsdatascience.com/dask-vs-vaex-for-big-data-38cb66728747)\n",
    "\n",
    "- [High performance Computing in Python](http://www.legendu.net/misc/blog/high-performance-computing-in-python)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}