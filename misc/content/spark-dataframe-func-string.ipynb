{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Ben Du\n",
    "- Date: 2020-06-17\n",
    "- Title: String Functions in Spark\n",
    "- Slug: spark-dataframe-func-string\n",
    "- Category: Computer Science\n",
    "- Tags: programming, Scala, Spark, DataFrame, string, round, Spark SQL, functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/2.1.1/api/java/index.html?org/apache/spark/sql/functions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e35ed06-a403-48aa-bdbc-5e4142842b38",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%classpath add mvn\n",
    "org.apache.spark spark-core_2.11 2.1.1\n",
    "org.apache.spark spark-sql_2.11 2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession$implicits$@6887b103"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val spark = SparkSession\n",
    "    .builder()\n",
    "    .master(\"local\")\n",
    "    .appName(\"string-sample\")\n",
    "    .config(\"spark.some.config.option\", \"some-value\")\n",
    "    .getOrCreate()\n",
    "spark\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacement Inside String\n",
    "\n",
    "Notice that `replace` is for replacing elements in a column \n",
    "NOT for replacemnt inside each string element.\n",
    "To replace substring with another one in a string,\n",
    "you have to use either `regexp_replace` or `translate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|month|\n",
      "+----------+-----+\n",
      "|2017/01/01|    1|\n",
      "|2017/02/01|    2|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val df = Seq(\n",
    "    (\"2017/01/01\", 1),\n",
    "    (\"2017/02/01\", 2)\n",
    ").toDF(\"date\", \"month\")\n",
    "df.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|month|\n",
      "+----------+-----+\n",
      "|2017-01-01|    1|\n",
      "|2017-02-01|    2|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"date\", regexp_replace($\"date\", \"/\", \"-\")).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## translate\n",
    "\n",
    "Notice that translate is different from usual replacemnt!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|month|\n",
      "+----------+-----+\n",
      "|2017-01-01|    1|\n",
      "|2017-02-01|    2|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"date\", translate($\"date\", \"/\", \"-\")).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substring\n",
    "\n",
    "1. Uses 1-based index.\n",
    "\n",
    "2. `substring` on `null` returns `null`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|month|\n",
      "+----------+-----+\n",
      "|2017/01/01|    1|\n",
      "|2017/02/01|    2|\n",
      "|      null|    3|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val df = Seq(\n",
    "    (\"2017/01/01\", 1),\n",
    "    (\"2017/02/01\", 2),\n",
    "    (null, 3)\n",
    ").toDF(\"date\", \"month\")\n",
    "df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----+\n",
      "|      date|month|year|\n",
      "+----------+-----+----+\n",
      "|2017/01/01|    1|2017|\n",
      "|2017/02/01|    2|2017|\n",
      "|      null|    3|null|\n",
      "+----------+-----+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"year\", substring($\"date\", 1, 4)).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|month|\n",
      "+----------+-----+\n",
      "|2017/01/01|   01|\n",
      "|2017/02/01|   02|\n",
      "|      null| null|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"month\", substring($\"date\", 6, 2)).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|month|\n",
      "+----------+-----+\n",
      "|2017/01/01|   01|\n",
      "|2017/02/01|   01|\n",
      "|      null| null|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"month\", substring($\"date\", 9, 2)).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|month|\n",
      "+----------+-----+\n",
      "|2017/01/01|    1|\n",
      "|2017/02/01|    2|\n",
      "|2018/02/05|    3|\n",
      "|      null|    4|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = Seq(\n",
    "    (\"2017/01/01\", 1),\n",
    "    (\"2017/02/01\", 2),\n",
    "    (\"2018/02/05\", 3),\n",
    "    (null, 4)\n",
    ").toDF(\"date\", \"month\")\n",
    "df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|month|\n",
      "+----------+-----+\n",
      "|2017/02/01|    2|\n",
      "|2018/02/05|    3|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter($\"date\" rlike \"\\\\d{4}/02/\\\\d{2}\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regex_extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "public static Column regexp_extract(Column e, String exp, int groupIdx)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|month|\n",
      "+----------+-----+\n",
      "|      2017|    1|\n",
      "|   2017/02|    2|\n",
      "|2018/02/05|    3|\n",
      "|      null|    4|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = Seq(\n",
    "    (\"2017\", 1),\n",
    "    (\"2017/02\", 2),\n",
    "    (\"2018/02/05\", 3),\n",
    "    (null, 4)\n",
    ").toDF(\"date\", \"month\")\n",
    "df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|      date|length(date)|\n",
      "+----------+------------+\n",
      "|      2017|           4|\n",
      "|   2017/02|           7|\n",
      "|2018/02/05|          10|\n",
      "|      null|        null|\n",
      "+----------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.length\n",
    "\n",
    "df.select($\"date\", length($\"date\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
