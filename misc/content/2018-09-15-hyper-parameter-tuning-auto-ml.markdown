Status: published
Date: 2020-01-27 16:35:20
Author: Ben Chuanlong Du
Title: Hyper Parameter Tuning and Automatical Machine Learning
Slug: ai-hyper-parameter-auto-ml
Category: AI
Tags: AI, machine learning, framework, AutoML, mlflow

**
Things on this page are fragmentary and immature notes/thoughts of the author.
It is not meant to readers but rather for convenient reference of the author and future improvement.
**


**
Things on this page are
fragmentary and immature notes/thoughts of the author.
It is not meant to readers
but rather for convenient reference of the author and future improvement.
**

## Methodology

hyper-parameter tuning, 
grid search
bayesian optimization 
evolutionary algorithms
genetic programming
cross validation
k-fold 
[Neural Architecture Search with Reinforcement Learning](https://openreview.net/pdf?id=r1Ue8Hcxg)

## Libraries

auto-sklearn


Apache Ray Tune

H2O AutoML

Python: H2OAutoML(...)

Driverless AI


tpot looks like a good one

## Platforms

[Google Cloud AutoML](https://cloud.google.com/automl/)


## Shared Resources of Models

[TensorFlow Hub](https://www.tensorflow.org/hub)

[Google AI Hub](https://cloud.google.com/ai-hub/)

[DAGsHub](https://dagshub.com/)
DAGsHub is a web platform for data version control and collaboration for data scientists and machine learning engineers.
It is like GitHub for data science and machine learning.

Kaggle

transformers

## References

https://arxiv.org/pdf/1908.00709v1.pdf

https://towardsdatascience.com/an-example-of-hyperparameter-optimization-on-xgboost-lightgbm-and-catboost-using-hyperopt-12bc41a271e

