{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title: Read/Write Files/Tables in Spark\n",
    "- Slug: spark-io\n",
    "- Date: 2019-11-27\n",
    "- Category: Programming\n",
    "- Tags: programming, Scala, Spark, IO, read, write, file, table\n",
    "- Author: Ben Du"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[DataFrameReader](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrameReader) \n",
    "APIs\n",
    "\n",
    "[DataFrameWriter](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrameWriter)\n",
    "APIs\n",
    "\n",
    "https://spark.apache.org/docs/latest/sql-programming-guide.html#data-sources\n",
    "\n",
    "## Comments\n",
    "\n",
    "1. It is suggested that you \n",
    "    [specify a schema when reading text files](https://stackoverflow.com/questions/39926411/provide-schema-while-reading-csv-file-as-a-dataframe).\n",
    "    If a schema is not specified when reading text files,\n",
    "    it is good practice to check the types of columns (as the types are inferred).\n",
    "    \n",
    "2. It is suggested that you use the `overwrite` mode when writing files/tables in Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/functions.html#input_file_name--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `input_file_name` in the package `org.apache.spark.sql.functions` \n",
    "creates a string column for the file name of the current Spark tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.write.option(\"compression\",\"none\").mode(\"overwrite\").save(\"testoutput.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.\n",
    "    mode(\"overwrite\").\n",
    "    format(\"parquet\").\n",
    "    option(\"compression\", \"none\").\n",
    "    save(\"/tmp/file_no_compression_parq\")\n",
    "df.write.\n",
    "    mode(\"overwrite\").\n",
    "    format(\"parquet\").\n",
    "    option(\"compression\", \"gzip\").\n",
    "    save(\"/tmp/file_with_gzip_parq\")\n",
    "df.write.\n",
    "    mode(\"overwrite\").\n",
    "    format(\"parquet\").\n",
    "    option(\"compression\", \"snappy\").\n",
    "    save(\"/tmp/file_with_snappy_parq\")\n",
    "\n",
    "df.write.mode(\"overwrite\").format(\"orc\").option(\"compression\", \"none\").mode(\"overwrite\").save(\"/tmp/file_no_compression_orc\")\n",
    "df.write.mode(\"overwrite\").format(\"orc\").option(\"compression\", \"snappy\").mode(\"overwrite\").save(\"/tmp/file_with_snappy_orc\")\n",
    "df.write.mode(\"overwrite\").format(\"orc\").option(\"compression\", \"zlib\").mode(\"overwrite\").save(\"/tmp/file_with_zlib_orc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode(\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option(\"compression\", \"none\")\n",
    "option(\"compression\", \"gzip\")\n",
    "option(\"compression\", \"snappy\")\n",
    "option(\"compression\", \"zlib\")\n",
    "\n",
    "option(\"inferSchema\", true)\n",
    ".option(\"nullValue\", \"NA\")\n",
    ".option(\"quote\", \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "",
   "name": "Scala",
   "nbconverter_exporter": "",
   "version": "2.11.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
