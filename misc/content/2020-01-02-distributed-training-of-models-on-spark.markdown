Status: published
Date: 2020-01-05 09:50:38
Author: Benjamin Du
Slug: distributed-training-of-models-on-spark
Title: Distributed Training of Models on Spark
Category: AI
Tags: AI, data science, machine learning, Spark, distributed computing

**
Things on this page are fragmentary and immature notes/thoughts of the author.
It is not meant to readers but rather for convenient reference of the author and future improvement.
**

## XGBoost

http://www.legendu.net/misc/blog/use-xgboost-with-spark/

## LightGBM

http://www.legendu.net/misc/blog/use-lightgbm-with-spark/

## [BigDL](https://github.com/intel-analytics/BigDL)

## [MMLSpark](https://github.com/Azure/mmlspark)

## Apache Ray

You can run Apache Ray on top of Spark via 
[analytics-zoo](https://github.com/intel-analytics/analytics-zoo).
But I'm not sure whether this is a good idea.

## TensorFlow

## PyTorch

## H2O

https://github.com/h2oai/sparkling-water
http://docs.h2o.ai/sparkling-water/2.2/latest-stable/doc/pysparkling.html
http://h2o-release.s3.amazonaws.com/h2o/master/4273/docs-website/h2o-docs/faq/sparkling-water.html
https://docs.databricks.com/_static/notebooks/h2o-sparkling-water-python.html

## References
